{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # “Synthetic Data for Label Balancing: Should You Use It and How?”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The developments in the field of Generative AI architectures also means higher quality tabular synthetic data (and it keeps getting better). Having worked with synthetic data, I’ve come across many articles that promote it as a catch-all solution for various obstacles (e.g. machine learning applications, privacy, ....). While synthetic data definitely is useful and has bright prospects (?), its usefulness and relevance is not always clearly assessed. An example of this is, and also the inspiration for writing this article, is the article provided by Synthetic Data Vault (SDV) titled: \"Can you use synthetic data for label balancing?\" (https://sdv.dev/blog/synthetic-label-balancing/).\n",
    "\n",
    "SDV’s article addresses a common challenge in classification: imbalanced target labels. Synthetic data is proposed as a 'compelling solution' for this problem compared to more traditional approaches without any empirical evidence.  Although you definitely can use synthetic data for label balancing (to answer the question of the article), the key question is whether you **should** use synthetic data and how it compares to state-of-the-art techniques.\n",
    "\n",
    "This article addresses the question of the article by SDV on whether you should use synthetic data for imbalanced classification tasks. It also demonstrates how to set up a proper cross-validation pipeline to prevent data leakage between training and holdout sets when applying resampling techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- Run the file and get results\n",
    "- Introduction\n",
    "- re-write section just below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Notably, to ensure a proper cross validation procedure, I use a pipeline. Specifically, the pipeline from imb_learn is used over sklearn's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt     \n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, train_test_split\n",
    "\n",
    "from sdv.metadata import Metadata\n",
    "from sdv.single_table import CTGANSynthesizer, TVAESynthesizer\n",
    "\n",
    "from helper_functions import NoiseSampler, SDVSampler, SDVENN, display_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "\n",
    "Finally, we define our random seed for reproducability, define the metrics we will use to evaluate our models, and define the CV folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 2\n",
    "\n",
    "SCORINGS = ['f1', 'roc_auc', 'precision', 'recall']\n",
    "\n",
    "CV_FOLDS = StratifiedKFold(n_splits = 5, random_state = RANDOM_STATE, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "\n",
    "For this analysis, the creditcard dataset will be used from Kaggle (https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud), containing transactions and whether they were fraudulent or not. To preserve privacy, most of the features are principal components derived from the original dataset. The goal is to predict whether a transaction is fraudulent or not, making it a classification task. Here the 'Class' variable indicates whether the transactions is fraudulent or not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard = pd.read_csv('./data/creditcard.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we see how our target labels are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    99.83\n",
       "1     0.17\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target label distribution rounded to 2 decimal places\n",
    "round(creditcard['Class'].value_counts(normalize = True) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally, the amount of non-fraudulent transactions outweigh the number of fraudulent transactions resulting in an imbalanced classification task. In this situation, the dataset is highly imbalanced, with  only 0.17% of transactions being fraudulent. This imbalance can pose challenges for machine learning models, which may become biased toward predicting the majority class. To address this issue, resampling methods are popular. These are methods to balance the dataset by increasing the minority class or by decreasing the majority class. And sometimes a combination of both, also called hybrid sampling.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**re-write for clarity below**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the techniques used to increase the minority class, i.e. oversampling, is through synthetic data as SDV suggests. But how does this approach perform and more importantly compare to other techniques?\n",
    "\n",
    "As you might be thinking (and I was too), this idea probably isn't very novel, and indeed similar research exists in the literature. The work of Adiputra and Wanchai (2024) caught my eye, which compares similar data-level approaches. However after snooping around in the repository containing the code for their research, I noticed in the validation synthetic data is generated **before** performing cross-validation, which is a common pitfall leading to data leakage and biased results.\n",
    "\n",
    "**Still explain/display what incorrect CV is below. Or at a later section. I can just mention here: 'why this is an issue and how this works will be displayed later/below**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting\n",
    "\n",
    "Next step is to split the data. We split the data into a CV set and a test set. We stratify on the target variable to ensure an even split across sets. The CV set will be used to perform cross validation on and the test will be the untouched data to showcase the effect of improper cross validation procedure and how this generalizes to truely unseen data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = creditcard.drop('Class', axis = 1)\n",
    "y = creditcard['Class']\n",
    "\n",
    "X_cv, X_test, y_cv, y_test = train_test_split(X, y, test_size = 0.2, stratify = y,\n",
    "                                                    random_state = RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorrect cross validation procedure \n",
    "\n",
    "Firstly, displaying what an incorrect cross validation setup looks like. Suppose we wish to use Random OverSampler, which balances the data by duplicating minority class instances, to randomly oversample the fraudulent transactions. A common mistake that is made, also made by Adiputra and Wanchai (2024), which inspired this blog, is to perform this resampling before splitting the data. \n",
    "\n",
    "This cross validation mistake is easily made and looks like this in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.9999\n"
     ]
    }
   ],
   "source": [
    "# We resample the data before performing cross-validation\n",
    "ros = RandomOverSampler(random_state = RANDOM_STATE)\n",
    "X_res, y_res = ros.fit_resample(X_cv, y_cv)\n",
    "\n",
    "# Feed the already resampled data into cross validation\n",
    "cv_score = cross_validate(\n",
    "    lgb.LGBMClassifier(random_state = RANDOM_STATE, n_jobs = -1, verbose = -1),\n",
    "    X_res, y_res, cv = CV_FOLDS, scoring = SCORINGS, n_jobs = -1\n",
    ")\n",
    "\n",
    "# Calculate the mean f1 score\n",
    "cv_score = cv_score['test_f1'].mean()\n",
    "print(f\"Cross validation score: {cv_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach leads to near perfect scores and this seems great, but how do these results translate to truly unseen data: the test set we have not used in the RandomOverSampler.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.8442\n"
     ]
    }
   ],
   "source": [
    "# We define the model and fit it to the resampled cv data\n",
    "lgbm_classifier = lgb.LGBMClassifier(random_state = RANDOM_STATE, n_jobs = -1, \n",
    "                                     verbose = -1)\n",
    "lgbm_classifier.fit(X_res, y_res)\n",
    "\n",
    "# predictions on the unseen data\n",
    "preds = lgbm_classifier.predict(X_test)\n",
    "test_score = f1_score(y_test, preds)\n",
    "print(f\"Test score: {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test results are noticeably lower than the cross-validation results, indicating that the cross-validation score obtained this way is not representative of the performance on truly unseen data. Furthermore, you might also want to tune hyperparameters during cross-validation. In this case, hyperparameters are selected based on an incorrect cross-validation procedure and overfit in that process, damaging generalization of your models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is going wrong?\n",
    "\n",
    "Although the difference may seem small, resampling before cross-validation can significantly affect the generalizability of results. The main idea behind creating a train and holdout split is to evaluate the model on data that it has not seen before. Cross-validation applies this same exact concept across multiple folds of the data to limit the variance of the results that come from making one single random split. In each fold, the holdout set is used as a separate unseen set of data to test the model on. Therefore, for each fold in the cross-validation procedure, no information from the holdout set should leak into the train set to ensure that it is still unseen.\n",
    "\n",
    "By using ROS before cross validation in this example, we create duplicates of fraud instances across the ENTIRE dataset. During cross-validation, these duplicated fraud instances can end up in the holdout set of a fold whereas the original ends up in the train set of a fold (or vice versa). As a result, the holdout set does not consist of truly unseen data and the model is tasked to predict the outcome of an observation it has already seen during training. \n",
    "\n",
    "To demonstrate this, we look at the exact duplicates across folds when ROS is used before and during cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add visual here????**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates amongst fraudulent transactions in the entire dataset: 0.0650\n"
     ]
    }
   ],
   "source": [
    "# Isolate fraudulent transactions\n",
    "X_pos = X[y == 1]\n",
    "\n",
    "# Determine the proportion of duplicates in the positive class\n",
    "prop_dupl = X_pos.duplicated(keep = False).sum() / X_pos.shape[0]\n",
    "print(f\"Duplicates amongst fraudulent transactions in the entire dataset: {prop_dupl:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates that approx. 6.5% of fraud instances are not unique. Using stratified folds, we would expect to see a similar percentage of duplicates for each fold throughout cross-validation. \n",
    "\n",
    "First, the number of duplicated fraud instances across folds are displayed for the data that is resampled before cross-validation, i.e. the X_res and y_res from earlier. Specifically, we look into how many duplicates there are between train and holdout for each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of duplicates in holdout set across folds: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Again, resampling the data before cross-validation\n",
    "ros = RandomOverSampler(random_state = RANDOM_STATE)\n",
    "X_res, y_res = ros.fit_resample(X_cv, y_cv)\n",
    "\n",
    "# to track the proportion of duplicates\n",
    "dupl_percentages = []\n",
    "\n",
    "# Loop over each fold using the already resampled data\n",
    "for i, (train_index, hd_index) in enumerate(CV_FOLDS.split(X_res, y_res)):\n",
    "    \n",
    "    # Obtain train and holdout sets for the current fold\n",
    "    X_train, X_hd = X_res.iloc[train_index], X_res.iloc[hd_index]\n",
    "    y_train, y_hd = y_res.iloc[train_index], y_res.iloc[hd_index]\n",
    "    \n",
    "    # Isolate the fraud instances\n",
    "    train_pos = X_train[y_train == 1]\n",
    "    hd_pos = X_hd[y_hd == 1]\n",
    "    \n",
    "    # Check the observations in holdout that are duplicates of the training set for fold i\n",
    "    mask = hd_pos.apply(tuple, axis = 1).isin(train_pos.apply(tuple, axis = 1))\n",
    "    duplicates = hd_pos[mask]\n",
    "    \n",
    "    # Determine the proportion of holdout observation that are duplicates\n",
    "    prop_dupl = duplicates.shape[0] / hd_pos.shape[0] * 100\n",
    "    dupl_percentages.append(prop_dupl)\n",
    "    \n",
    "print(f\"Proportion of duplicates in holdout set across folds: {np.mean(dupl_percentages):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When resampling is performed before cross-validation, the average percentage of duplicates across folds reaches 100%. This means that every fraud instance in the holdout set is a duplicate of an observation in the training set, explaining the near perfect F1-scores observed earlier.\n",
    "\n",
    "While the high duplication rate is largely attributed to the severe class imbalance in this dataset, the issue may manifest more subtly in other contexts. Moreover, data leakage will not always appear as exact duplicates for all synthesizers. For example, a synthesizer might avoid creating exact duplicates but still generate numerous highly similar observations. Therefore, one should also understand the behavior of the synthesizer used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well... how do you resample the correct way?\n",
    "\n",
    "There are multiple ways to do it. Namely, iterating over each fold in a loop and applying the transformations to the train and holdout set separately. The manual approach below is used to get a feel of how the transformations should look like and what is exactly is going wrong in the previous setup. Afterwards, a pipeline will be used for a more efficient setup. \n",
    "\n",
    "The correct way to resample is performed by iterating over the unresampled data and only then applying resampling WITHIN each fold as opposed to beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score with correct CV procedure: 0.8384\n"
     ]
    }
   ],
   "source": [
    "# track the test scores for each fold and average them afterwards\n",
    "cv_results = []\n",
    "\n",
    "# Loop over the folds of the data that is NOT resampled beforehand\n",
    "for i, (train_index, hd_index) in enumerate(CV_FOLDS.split(X_cv, y_cv)):\n",
    "    \n",
    "    # Obtain train and holdout sets for fold i\n",
    "    X_train, X_hd = X_cv.iloc[train_index], X_cv.iloc[hd_index]\n",
    "    y_train, y_hd = y_cv.iloc[train_index], y_cv.iloc[hd_index]\n",
    "    \n",
    "    # Applying the ROS to the training set WITHIN each fold as opposed to beforehand \n",
    "    ros = RandomOverSampler(random_state = RANDOM_STATE)\n",
    "    X_train_res, y_train_res = ros.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Fit the model to the resampled train set and predict the holdout set that is not resampled\n",
    "    lgb_clf = lgb.LGBMClassifier(random_state = RANDOM_STATE, n_jobs = -1, verbose = -1)\n",
    "    lgb_clf.fit(X_train_res, y_train_res)\n",
    "    cv_preds = lgb_clf.predict(X_hd)\n",
    "    \n",
    "    # Calculate and append F1 score for the current fold\n",
    "    cv_score = f1_score(y_hd, cv_preds)\n",
    "    cv_results.append(cv_score)\n",
    "    \n",
    "print(f\"F1 score with correct CV procedure: {np.mean(cv_results):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the score is less impressive than the first method, it more accurately reflects the results on the truly unseen holdout set of 0.8442. And how is this reflected in the duplicates in the holdout set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of duplicates in test set across folds: 6.35%\n"
     ]
    }
   ],
   "source": [
    "# Again, we track the proportion of duplicates \n",
    "dupl_percentages = []\n",
    "\n",
    "for i, (train_index, hd_index) in enumerate(CV_FOLDS.split(X_cv, y_cv)):\n",
    "   \n",
    "    # Obtain train and holdout sets for fold i\n",
    "    X_train, X_hd = X_cv.iloc[train_index], X_cv.iloc[hd_index]\n",
    "    y_train, y_hd = y_cv.iloc[train_index], y_cv.iloc[hd_index]\n",
    "    \n",
    "    # WITHIN each fold, we resample the training set\n",
    "    ros = RandomOverSampler(random_state = RANDOM_STATE)\n",
    "    X_res, y_res = ros.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Only then do we isolate the positive class\n",
    "    train_pos = X_res[y_res == 1]\n",
    "    hd_pos = X_hd[y_hd == 1]\n",
    "    \n",
    "    # Check to see the observations in holdout that are duplicates of the training set\n",
    "    mask = hd_pos.apply(tuple, axis = 1).isin(train_pos.apply(tuple, axis = 1))\n",
    "    duplicates = hd_pos[mask]\n",
    "    \n",
    "    # determine the proportion of holdout observation that are duplicates\n",
    "    prop_dupl = duplicates.shape[0] / hd_pos.shape[0] * 100\n",
    "    dupl_percentages.append(prop_dupl)\n",
    "    \n",
    "print(f\"Proportion of duplicates in test set across folds: {np.mean(dupl_percentages):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stayed here with check**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we can see that the proportion of duplicates across folds resembles that of the one we obtained from the entire dataset, indicating that resampling within each fold leads to folds that are more representative. Furthermore, the effect of improper cross validation procedure in this example with ROS is clear in this situation due to the large amount of exact duplicates. However, depending on the severity of class imbalance, the synthetic data generator used, and the degree to which the generator may overfit, this data leakage issue might be less obvious. \n",
    "\n",
    "Moreover, this issue of data leakge between train and holdout is not something that only pertains to resampling methods in imbalanced classification tasks. This also applies to other, perhaps more subtle, forms of data leakage, such as feature engineering methods that use information from observations that will end up in the holdout set during cross validation. Think of scaling for instance. Ideally, a scaler should be fit only on the training set and then applied to both training and holdout sets, repeating this for each fold in cross-validation. \n",
    "\n",
    "Though not all feature engineering has to lead to data leakage between train and holdout. For instance, the encoding of a categorical gender variable from male/female to binary, which typically is fine since the information is contained within the rows. However, this might get a bit tricky when working with a high cardinality categorical variable where certain values are quite rare meaning that they might appear in the hold out set but not in the train set. For this reason, it's important to be aware of what transformations are being applied, when they are applied, and what information they rely on. Best practice is to perform all transformations within cross-validation rather than beforehand to prevent data leakage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that we know how to evaluate resampling techniques during cross-validation, what is the best way to deal with the imbalance?\n",
    "\n",
    "As previously mentioned, imbalanced datasets can lead to biased results towards the larger class. Ways to deal with this can be categorized into data level and algorithm level approaches. Data level approaches are techniques that artificially over/under/hybrid sample observations to balance the dataset. Whereas algorithm level approaches don't do anything to the underlying data, but to the algorithm to deal with this imbalance in the dataset\n",
    "\n",
    "The data level approaches we use firstly include ROS, noise injection, and synthetic data as covered in SDV's article. While ROS is a common oversampling technique, noise injection is less familiar in practice, and since the article doesn't detail the noise generation process, I assume values are randomly sampled from a normal distribution. Synthetic data generation creates artificially generated observations of the minority class by learning the underlying data patterns. In this scenario, the synthetic data should ideally resemble real observations to help improve model performance. This resemblance is called having high fidelity. However, excessively high fidelity risks creating exact copies of the original data, which can result from the generator overfitting to the data.\n",
    "\n",
    "The techniques we use to generate synthetic data are Synthetic Minority Over-sampling TEchnique (SMOTE), Conditional Tabular Generative Adversarial Networks (CTGAN), and Tabular Variational Auto Encoder (TVAE), for which we will use SDV's library for the latter two. SMOTE generates synthetic examples of the minority class by interpolating between observations based on their feature space distance, whereas CTGAN and TVAE use neural networks to learn data representations and generate samples without relying on explicit distance-based interpolation.\n",
    "\n",
    "Furthermore, we also use an algorithm-level approach: cost-sensitive learning (CSL). CSL applies different weights to observations so that the model learns to minimize the costs associated with misclassifying observations based on their importance. In this context, fraud instances are given higher weights, meaning a larger penalty is assigned to misclassifying fraudulent transactions. CSL is particularly effective when you know the exact costs of misclassification. Since the true misclassification costs are unknown in this context, we use inverse class frequency as the weighting scheme, which assigns higher weights to the rarer fraud class.\n",
    "\n",
    "Given that the folds are stratified, we assume the that the assigned weights calculated on the entire train set is equal to the weights for each fold. This will result in the following weights being assigned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority class weight: 0.5009, minority class weight: 289.4380\n"
     ]
    }
   ],
   "source": [
    "w1, w2 = X.shape[0] / (2 * np.bincount(y)) \n",
    "print(f\"Majority class weight: {w1:.4f}, minority class weight: {w2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, inspired by Adiputra and Wanchai (2024), we also use hybrid sampling. Specifically, we will throw SMOTE-ENN and their proposed CTGAN-ENN into the mix, which combine oversampling with downsampling using Edited Nearest Neighbors, which removes observations from the majority class that are close to the decision boundary. CTGAN-ENN has been shown to provide improved performance over CSL and other over- and hybrid sampling techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data level approaches/Pipeline display (i will skip over the individual codes)\n",
    "\n",
    "Previously, we have performed cross validation by manually looping over the folds. Although this provides a lot of control, there is an easier and cleaner way to do it. We can use a Pipeline to perform the same operations. A Pipeline offers a more concise and is an easy to use alternative. The pipelines used will ensure that transformations are always fit on the train set within each fold and subsequently transforming the holdout set, reducing the risk of data leakage.\n",
    "\n",
    "In this article, we use the Pipeline from the imblearn package. While scikit-learn’s Pipeline can also handle transformations between training and test sets, imblearn’s version supports samplers, making it more suitable for our workflow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random OverSampling pipeline example 1\n",
    "\n",
    "\n",
    "First, we define the classifier to be used in the pipeline (and in other pipelines). In this example, we arbitrarily choose the LightGBM classifier, but you could replace this with any classifier of your choosing. Next, we construct the pipeline, which includes the preprocessing steps (e.g., our RandomOverSampler, which can be directly passed into the pipeline) followed by the classifier. Finally, we pass this pipeline into the cross_validate function, which handles resampling within each fold, which was previously performed manually, and evaluates the model’s performance across folds using the metrics defined in our SCORINGS list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LightGBM classifier to be used in the pipeline\n",
    "lgb_clf = lgb.LGBMClassifier(random_state=RANDOM_STATE, n_jobs=-1, verbose=-1)\n",
    "\n",
    "# Define the sampling pipeline\n",
    "pipeline_ros = Pipeline(\n",
    "    [('ros', RandomOverSampler(random_state = RANDOM_STATE)),\n",
    "     ('lgbm', lgb_clf)] \n",
    ")\n",
    "\n",
    "cv_score_ros = cross_validate(pipeline_ros, X, y, cv = CV_FOLDS, scoring = SCORINGS, \n",
    "                               n_jobs = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise injection\n",
    "\n",
    "**not shown in blog, only result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_noise = Pipeline(\n",
    "    [('noise_sampler', NoiseSampler(random_state = RANDOM_STATE)),\n",
    "     ('lgbm', lgb_clf)]\n",
    ")\n",
    "\n",
    "cv_score_noise = cross_validate(pipeline_noise, X, y, cv = CV_FOLDS, scoring = SCORINGS, \n",
    "                                n_jobs = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE\n",
    "\n",
    "**not shown in blog, only result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_smote = Pipeline(\n",
    "    [('scaler', StandardScaler()),\n",
    "     ('smote', SMOTE(random_state = RANDOM_STATE)),\n",
    "     ('lgbm', lgb_clf)]\n",
    ")\n",
    "\n",
    "cv_score_smote = cross_validate(pipeline_smote, X, y, cv = CV_FOLDS, scoring = SCORINGS, \n",
    "                                n_jobs = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SDV Generators\n",
    "\n",
    "In order to use SDV's synthetic data generators, we first need to define the metadata of the dataset used. This can simply be done with with the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first define the metadata for the SDV synthesizers\n",
    "metadata = Metadata.detect_from_dataframe(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to update the metadata manually if you wish. Furthermore, SDV offers a wide variety of synthetic data generators, as well as many functions and parameters to try to improve the quality of the synthetic data. Namely, SDV provides useful preprocessing tools and constraints (i.e., deterministic rules the synthetic data should adhere to) to incorporate domain knowledge and business rules. Since the other methods used in this article work out of the box, I will not be applying any of these methods and will compare them in the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CTGAN Pipeline example 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrating CTGAN into a pipeline is a bit more involved since there is no standard support for it. Therefore, we have to build our custom resampling class, which we can pass into the pipeline.\n",
    "\n",
    "We build a BaseSampler class we can use for all resampling procedures that are not natively supported in the Pipeline from imb_learn (i.e. CTGAN, TVAE, and the custom noise sampling procedure). This BaseSampler contains all the base functiontality that is consistent across these samplers and ensures that during cross-validation, resampling happens within each fold while keeping the training and holdout sets properly separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaseEstimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mBaseSampler\u001b[39;00m(\u001b[43mBaseEstimator\u001b[49m):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Base class for all custom samplers.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, random_state):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BaseEstimator' is not defined"
     ]
    }
   ],
   "source": [
    "class BaseSampler(BaseEstimator):\n",
    "    \"\"\"Base class for all custom samplers.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, random_state):\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def fit_resample(self, X, y):\n",
    "        \"\"\"Fit the sampler to the data and return the resampled data\"\"\"\n",
    "        return self.resample(X, y)\n",
    "    \n",
    "    def _get_num_samples(self, y):\n",
    "        \"\"\"Get the number of samples to generate for the minority class for this binary\n",
    "        classification problem.\"\"\"\n",
    "        y_values = y.value_counts()\n",
    "        num_samples = y_values[0] - y_values[1]\n",
    "        \n",
    "        return num_samples  \n",
    "\n",
    "    def resample(self, X, y):\n",
    "        \"\"\"Resample the data using the specified sampling method\"\"\"\n",
    "        \n",
    "        X_train = X.copy()\n",
    "        y_train = y.copy()\n",
    "        \n",
    "        num_samples = self._get_num_samples(y_train)\n",
    "\n",
    "        # Obtain the minority class that needs to be upsampled\n",
    "        X_minority = X_train[y_train == 1]\n",
    "        \n",
    "        X_upsampled = self._generate_syn_data(X_minority, num_samples)\n",
    "\n",
    "        # Updating indepent variables and the target variable\n",
    "        X_sampled = pd.concat([X_train, X_upsampled], axis = 0)\n",
    "        y_sampled = pd.concat([y_train, pd.Series(np.ones(num_samples))], axis = 0)\n",
    "\n",
    "        return X_sampled, y_sampled\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the SDVSampler class for the CTGAN and TVAE synthesizers, based on BaseSampler as its parent class. This class takes the synthesizer generator in the __init__ method and has a custom _generate_syn_data() function to resample using the SDV synthesizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SDVSampler(BaseSampler):  \n",
    "    \n",
    "    def __init__(self, generator, metadata, random_state):\n",
    "        super().__init__(random_state)\n",
    "        self.generator = generator\n",
    "        self.metadata = metadata\n",
    "       \n",
    "    def _generate_syn_data(self, X_minority, num_samples):\n",
    "        \"\"\"Generate synthetic data using the SDV synthesizer.\"\"\"\n",
    "        \n",
    "        X_resample = X_minority.copy()\n",
    "        \n",
    "        # Creating a new instance of the synthesizer within each fold\n",
    "        synthesizer = self.generator(self.metadata)\n",
    "\n",
    "        synthesizer.fit(X_resample)\n",
    "        X_sds = synthesizer.sample(num_samples)\n",
    "        \n",
    "        return X_sds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final pipeline for CTGAN then looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.single_table import CTGANSynthesizer\n",
    "\n",
    "# Define the CTGAN pipeline using our custom SDVSampler class\n",
    "pipeline_ctgan = Pipeline(\n",
    "    [('ctgan', SDVSampler(CTGANSynthesizer, metadata, random_state = RANDOM_STATE)),\n",
    "     ('lgbm', lgb_clf)]\n",
    ")\n",
    "\n",
    "cv_score_ctgan = cross_validate(pipeline_ctgan, X, y, cv = CV_FOLDS, scoring = SCORINGS, \n",
    "                               n_jobs = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TVAE Synthesizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_tvae = Pipeline(\n",
    "    [('tvae', SDVSampler(TVAESynthesizer, metadata, random_state = RANDOM_STATE)),\n",
    "     ('lgbm', lgb_clf)]\n",
    ")\n",
    "\n",
    "cv_score_tvae = cross_validate(pipeline_tvae, X, y, cv=CV_FOLDS, scoring = SCORINGS,\n",
    "                               n_jobs = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE ENN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m pipeline_smoteenn \u001b[38;5;241m=\u001b[39m Pipeline(\n\u001b[0;32m      2\u001b[0m     [(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, StandardScaler()),\n\u001b[0;32m      3\u001b[0m      (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmote enn\u001b[39m\u001b[38;5;124m'\u001b[39m, SMOTEENN(random_state \u001b[38;5;241m=\u001b[39m RANDOM_STATE)),\n\u001b[0;32m      4\u001b[0m      (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlgbm\u001b[39m\u001b[38;5;124m'\u001b[39m, lgb_clf)]\n\u001b[0;32m      5\u001b[0m )\n\u001b[1;32m----> 7\u001b[0m cv_score_smoteenn \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline_smoteenn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mCV_FOLDS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSCORINGS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tayyi\\anaconda3\\envs\\imb_syn\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\tayyi\\anaconda3\\envs\\imb_syn\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:411\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    410\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 411\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    431\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tayyi\\anaconda3\\envs\\imb_syn\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tayyi\\anaconda3\\envs\\imb_syn\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\tayyi\\anaconda3\\envs\\imb_syn\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tayyi\\anaconda3\\envs\\imb_syn\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipeline_smoteenn = Pipeline(\n",
    "    [('scaler', StandardScaler()),\n",
    "     ('smote enn', SMOTEENN(random_state = RANDOM_STATE)),\n",
    "     ('lgbm', lgb_clf)]\n",
    ")\n",
    "\n",
    "cv_score_smoteenn = cross_validate(pipeline_smoteenn, X, y, cv = CV_FOLDS, scoring = SCORINGS, \n",
    "                                n_jobs = -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CTGAN ENN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m pipeline_ctganenn \u001b[38;5;241m=\u001b[39m Pipeline(\n\u001b[0;32m      2\u001b[0m     [(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mctgan\u001b[39m\u001b[38;5;124m'\u001b[39m, SDVENN(CTGANSynthesizer, metadata, random_state \u001b[38;5;241m=\u001b[39m RANDOM_STATE)),\n\u001b[0;32m      3\u001b[0m      (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLGB\u001b[39m\u001b[38;5;124m'\u001b[39m, lgb\u001b[38;5;241m.\u001b[39mLGBMClassifier(random_state \u001b[38;5;241m=\u001b[39m RANDOM_STATE, n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))]\n\u001b[0;32m      4\u001b[0m )\n\u001b[1;32m----> 6\u001b[0m cv_score_ctganenn \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline_ctganenn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mCV_FOLDS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSCORINGS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tayyi\\anaconda3\\envs\\imb_syn\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\tayyi\\anaconda3\\envs\\imb_syn\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:411\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    410\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 411\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    431\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tayyi\\anaconda3\\envs\\imb_syn\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tayyi\\anaconda3\\envs\\imb_syn\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tayyi\\anaconda3\\envs\\imb_syn\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tayyi\\anaconda3\\envs\\imb_syn\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipeline_ctganenn = Pipeline(\n",
    "    [('ctgan', SDVENN(CTGANSynthesizer, metadata, random_state = RANDOM_STATE)),\n",
    "     ('lgnm', lgb_clf)]\n",
    ")\n",
    "\n",
    "cv_score_ctganenn = cross_validate(pipeline_ctganenn, X, y, cv = CV_FOLDS, \n",
    "                                   scoring = SCORINGS, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm level approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost sensitive learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sampling pipeline\n",
    "pipeline_csl = Pipeline(\n",
    "    [('LGB', lgb.LGBMClassifier(class_weight= 'balanced', random_state = RANDOM_STATE,\n",
    "                                n_jobs = -1, verbose = -1))]\n",
    ")\n",
    "\n",
    "cv_score_csl = cross_validate(pipeline_csl, X, y, cv=CV_FOLDS, scoring = SCORINGS,\n",
    "                               n_jobs = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = [cv_score_noise, cv_score_ros, cv_score_smote, cv_score_ctgan, cv_score_tvae, \n",
    "             cv_score_smoteenn, cv_score_ctganenn, cv_score_csl]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc_auc</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Noise</th>\n",
       "      <td>0.708</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROS</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTE</th>\n",
       "      <td>0.654</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTGAN</th>\n",
       "      <td>0.764</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TVAE</th>\n",
       "      <td>0.763</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Copula</th>\n",
       "      <td>0.847</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSL</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    F1  Roc_auc  Precision  Recall\n",
       "Baseline         0.000    0.499      0.000   0.000\n",
       "Noise            0.708    0.974      0.626   0.819\n",
       "ROS              0.837    0.975      0.862   0.815\n",
       "SMOTE            0.654    0.961      0.538   0.837\n",
       "CTGAN            0.764    0.971      0.721   0.817\n",
       "TVAE             0.763    0.967      0.715   0.821\n",
       "Gaussian Copula  0.847    0.978      0.906   0.797\n",
       "CSL              0.839    0.975      0.843   0.835"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Complete the scores of \n",
    "r = display_scores(cv_scores, SCORINGS)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian copula provides the best F1, which is kind of surprising. This is likely very dataset dependent and to rule out/for synthetic data, this process should in actuality be repeated for multiple datasets, which I don't have the time to do. Perhaps I should add a quick section: 'Understanding the data', since the dataset at hand might be over simplistic.\n",
    "\n",
    "However, the Gaussian Copula provides the worsy recall of all methods (and best precision). For the other methods, this is more aligned with each other. So, it would also still be dependent on how you want to use the model and the cost of misclassification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- Highlight how CTGAN-ENN compares against SMOTE-ENN and all in general\n",
    "- Based on the mediocre results from SMOTE experiment with fewer examples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imb_syn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
