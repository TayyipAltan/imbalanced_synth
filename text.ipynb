{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1125261",
   "metadata": {},
   "source": [
    "# “Synthetic Data for Label Balancing: Should You Use It and How?”\n",
    "\n",
    "AOver the past six months working with tabular synthetic data, I’ve come across many articles that promote it as a catch-all solution for various machine learning challenges. While synthetic data can serve as a useful Privacy Enhancing Technology (PET) and has shown to be useful in certain tasks, its usefulness and relevance is not always clearly assessed. An example of this is, and also the inspiration for me writing this article, is the article provided by Synthetic Data Vault (SDV) titled: \"Can you use synthetic data for label balancing?\" (https://sdv.dev/blog/synthetic-label-balancing/).\n",
    "\n",
    "SDV’s article addresses a common challenge in classification: imbalanced target labels. It discusses traditional data-level solutions such as noise injection and Random Oversampling (ROS), correctly noting their limitations. However, it then proposes synthetic data as a 'compelling solution' without any empirical evidence. While I am a fan of SDV’s generators, constraints, and preprocessors, this article overlooks important aspects of evaluating synthetic data for label balancing. Although you definitely can use synthetic data for label balancing (to answer the question of the article), the key question is whether you **should** use synthetic data and how it compares to state-of-the-art techniques. Throughout this article, I aim to provide an answer to this question by comparing synthetic data produced by SDV generators against other techniques. Specifically, I compare various data-level and algorithm-level approaches against SDV synthesizers.\n",
    "\n",
    "As you might be thinking (and I was too), this idea probably isn't very novel, and indeed similar research exists in the literature. The work of Adiputra and Wanchai (2024) caught my eye, which compares similar data-level approaches. However, their validation approach uses cross validation (CV) with synthetic data being generated before CV, which is a common pitfall leading to data leakage and biased results. (Also a mistake in section 5.7.4 of: https://d2l.ai/chapter_multilayer-perceptrons/kaggle-house-price.html. It is not the exact same mistake, but similar. Transformations should be applied separately so doesnt really. Mention this in the conclusion that you should also split other feature engineering methods in CV)\n",
    "\n",
    "This article aims to provide an answer to the question of the article by SDV whether you should use synthetic data for imbalanced classification tasks. Furthermore, this article also aims to address pitfalls in cross validation leading to data leakage between train and holdout fold, why this is problematic, and how you can correctly set up a CV procedure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed913e07",
   "metadata": {},
   "source": [
    "# Other sources:\n",
    "\n",
    "- https://towardsdatascience.com/how-i-won-the-mostly-ai-synthetic-data-challenge/\n",
    "- https://towardsdatascience.com/confusion-matrix-made-simple-accuracy-precision-recall-f1-score/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58767d7b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d264cf2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df681e0f",
   "metadata": {},
   "source": [
    "To align with TDS guidelines, check other articles: https://towardsdatascience.com/tag/editors-pick/\n",
    "\n",
    "Check guidelines: https://towardsdatascience.com/questions-96667b06af5/#How-To-Submit-Your-Work\n",
    "Check FAQ: https://towardsdatascience.com/writers-faq-462571b65b35/#ai\n",
    "\n",
    "Maybe I can leave some of the code in the pipelines out since it is repetitive?\n",
    "\n",
    "Add some visuals as well. Perhaps a visual representation of cross validation mistakes.\n",
    "\n",
    "\n",
    "To keep it concise, maybe remove SMOTE and SMOTE-ENN for ADASYN??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e39cd3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d6df6a9",
   "metadata": {},
   "source": [
    "Explain why I write this article\n",
    "\n",
    "- I know that we could use synthetic data from SDV, but shoiuld you?\n",
    "- Idea not very new, so I went and found literature\n",
    "- Found the paper and was curious about the underlying code\n",
    "- Found that the code applied incorrect CV\n",
    "- Explain what incorrect CV is in short and then display it below?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54128fb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cbd717a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c86f5c6",
   "metadata": {},
   "source": [
    "# Actual idea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260ef09f",
   "metadata": {},
   "source": [
    "Explain data level and algorithm level approaches in short\n",
    "\n",
    "- Traditional resampling techniques\n",
    "    - Make distinction between over/uner/hybrid sampling\n",
    "    - Traditional resampling techniques (including noise)\n",
    "- what is synthetic data?\n",
    "    - Synthetic data techniques used\n",
    "- Hybrid sampling\n",
    "    - based on the papers\n",
    "- And cost sensitive learning\n",
    "- We combine those results.\n",
    "\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "\n",
    "data level: oversampling (mention all techniques I'll be covering: Random oversampling, SMOTE Noise injection from the original article, SDV (CTGAN and TVAE)), hybrid sampling (since I am curious about the results of Adiputra and Wanchai (2024) :))\n",
    "\n",
    "\n",
    "algorithm level: only consist of cost sensitive learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296ac166",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
